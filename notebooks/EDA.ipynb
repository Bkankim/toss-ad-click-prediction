{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c083263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA Merlin 기반 안전한 CTR 데이터 분석\n",
    "# RTX 3090 24GB 최적화 버전\n",
    "\n",
    "import cupy as cp\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335a01da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 NVIDIA Merlin CTR 분석 시작\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"🚀 NVIDIA Merlin CTR 분석 시작\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. 환경 확인 및 라이브러리 import\n",
    "def check_environment():\n",
    "    \"\"\"환경 및 라이브러리 확인\"\"\"\n",
    "    print(\"🔍 환경 확인 중...\")\n",
    "    \n",
    "    required_libs = {\n",
    "        'cudf': '23.10+',\n",
    "        'cupy': '12.0+', \n",
    "        'nvtabular': '23.08+',\n",
    "        'pandas': '1.5+',\n",
    "        'pyarrow': '12.0+'\n",
    "    }\n",
    "    \n",
    "    available_libs = {}\n",
    "    \n",
    "    # CuDF 확인\n",
    "    try:\n",
    "        import cudf\n",
    "        available_libs['cudf'] = cudf.__version__\n",
    "        print(f\"✅ cuDF {cudf.__version__} 사용 가능\")\n",
    "    except ImportError:\n",
    "        print(\"❌ cuDF 없음 - GPU 가속 불가\")\n",
    "        available_libs['cudf'] = None\n",
    "    \n",
    "    # CuPy 확인  \n",
    "    try:\n",
    "        import cupy as cp\n",
    "        available_libs['cupy'] = cp.__version__\n",
    "        print(f\"✅ CuPy {cp.__version__} 사용 가능\")\n",
    "        \n",
    "        # GPU 메모리 확인\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        print(f\"🎯 GPU 메모리 풀 초기화 완료\")\n",
    "    except ImportError:\n",
    "        print(\"❌ CuPy 없음 - GPU 메모리 관리 제한\")\n",
    "        available_libs['cupy'] = None\n",
    "    \n",
    "    # NVTabular 확인\n",
    "    try:\n",
    "        import nvtabular as nvt\n",
    "        available_libs['nvtabular'] = nvt.__version__\n",
    "        print(f\"✅ NVTabular {nvt.__version__} 사용 가능\")\n",
    "    except ImportError:\n",
    "        print(\"❌ NVTabular 없음 - Merlin 기능 불가\")\n",
    "        available_libs['nvtabular'] = None\n",
    "    \n",
    "    # 기본 라이브러리들\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import pyarrow.parquet as pq\n",
    "        import numpy as np\n",
    "        available_libs['pandas'] = pd.__version__\n",
    "        available_libs['pyarrow'] = pq.__version__ if hasattr(pq, '__version__') else 'available'\n",
    "        print(f\"✅ Pandas {pd.__version__}, PyArrow 사용 가능\")\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ 기본 라이브러리 오류: {e}\")\n",
    "    \n",
    "    return available_libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5d7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 환경 확인 중...\n",
      "✅ cuDF 23.10.02 사용 가능\n",
      "✅ CuPy 13.6.0 사용 가능\n",
      "🎯 GPU 메모리 풀 초기화 완료\n",
      "❌ NVTabular 없음 - Merlin 기능 불가\n",
      "✅ Pandas 1.5.3, PyArrow 사용 가능\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 환경 확인 실행\n",
    "libs = check_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e4bf169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. GPU 메모리 관리 함수들\n",
    "def print_gpu_memory():\n",
    "    \"\"\"GPU 메모리 사용량 출력\"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        used = mempool.used_bytes() / 1024**3\n",
    "        total = mempool.total_bytes() / 1024**3 if mempool.total_bytes() > 0 else 24.0  # RTX 3090 기준\n",
    "        print(f\"🎯 GPU 메모리: {used:.1f}GB / {total:.1f}GB\")\n",
    "        return used, total\n",
    "    except:\n",
    "        print(\"🎯 GPU 메모리 정보 확인 불가\")\n",
    "        return 0, 0\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"GPU 메모리 정리\"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        mempool.free_all_blocks()\n",
    "        gc.collect()\n",
    "        print(\"🧹 GPU 메모리 정리 완료\")\n",
    "    except:\n",
    "        gc.collect()\n",
    "        print(\"🧹 CPU 메모리 정리 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26fe499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 GPU 메모리: 0.0GB / 24.0GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 24.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 초기 메모리 상태 확인\n",
    "print_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab1cea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 파일 분석: ../data/train.parquet\n",
      "   📊 행 수: 10,704,179\n",
      "   📊 컬럼 수: 119\n",
      "   📊 파일 크기: 8.19 GB\n",
      "   📊 Row Groups: 1\n",
      "📁 파일 분석: ../data/test.parquet\n",
      "   📊 행 수: 1,527,298\n",
      "   📊 컬럼 수: 119\n",
      "   📊 파일 크기: 1.20 GB\n",
      "   📊 Row Groups: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. 파일 기본 정보 확인 (메모리 안전)\n",
    "def safe_file_info(file_path):\n",
    "    \"\"\"파일 정보를 안전하게 확인\"\"\"\n",
    "    try:\n",
    "        import pyarrow.parquet as pq\n",
    "        \n",
    "        print(f\"📁 파일 분석: {file_path}\")\n",
    "        \n",
    "        # 파일 존재 확인\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"❌ 파일이 존재하지 않습니다: {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # 파케이 파일 메타데이터만 읽기\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        file_info = {\n",
    "            'rows': pf.metadata.num_rows,\n",
    "            'columns': len(pf.schema),\n",
    "            'file_size_gb': os.path.getsize(file_path) / 1024**3,\n",
    "            'row_groups': pf.num_row_groups,\n",
    "            'column_names': pf.schema.names\n",
    "        }\n",
    "        \n",
    "        print(f\"   📊 행 수: {file_info['rows']:,}\")\n",
    "        print(f\"   📊 컬럼 수: {file_info['columns']}\")\n",
    "        print(f\"   📊 파일 크기: {file_info['file_size_gb']:.2f} GB\")\n",
    "        print(f\"   📊 Row Groups: {file_info['row_groups']}\")\n",
    "        \n",
    "        return file_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 파일 정보 확인 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 파일 정보 확인\n",
    "train_info = safe_file_info('../data/train.parquet')\n",
    "test_info = safe_file_info('../data/test.parquet')\n",
    "\n",
    "if not train_info:\n",
    "    print(\"⚠️ train.parquet 파일 경로를 확인해주세요\")\n",
    "    print(\"현재 디렉토리:\", os.getcwd())\n",
    "    print(\"파일 목록:\", [f for f in os.listdir('.') if f.endswith('.parquet')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74aa495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. CuDF 기반 안전한 샘플 분석\n",
    "def cudf_safe_sample_analysis(file_path, sample_size=50000):\n",
    "    \"\"\"CuDF를 사용한 안전한 샘플 분석\"\"\"\n",
    "    \n",
    "    if not libs.get('cudf'):\n",
    "        print(\"❌ CuDF가 설치되지 않아 GPU 분석 불가\")\n",
    "        return fallback_pandas_analysis(file_path, sample_size)\n",
    "    \n",
    "    try:\n",
    "        import cudf\n",
    "        import cupy as cp\n",
    "        \n",
    "        print(f\"🎯 CuDF 기반 샘플 분석 시작 (샘플 크기: {sample_size:,})\")\n",
    "        \n",
    "        clear_gpu_memory()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 작은 청크로 시작\n",
    "        chunk_size = min(sample_size, 10000)\n",
    "        print(f\"   청크 크기: {chunk_size:,}행\")\n",
    "        \n",
    "        # 파케이 파일에서 첫 번째 row group 읽기\n",
    "        import pyarrow.parquet as pq\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        # 첫 번째 청크를 pandas로 읽고 cudf로 변환\n",
    "        first_chunk_pd = pf.read_row_group(0, columns=None).to_pandas()\n",
    "        \n",
    "        # 샘플 크기에 맞게 자르기\n",
    "        if len(first_chunk_pd) > sample_size:\n",
    "            first_chunk_pd = first_chunk_pd.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        print(f\"   Pandas 청크 로드 완료: {len(first_chunk_pd):,}행\")\n",
    "        \n",
    "        # CuDF로 변환\n",
    "        sample_gdf = cudf.from_pandas(first_chunk_pd)\n",
    "        print(f\"   CuDF 변환 완료\")\n",
    "        \n",
    "        # GPU에서 기본 분석 수행\n",
    "        print(f\"🔍 GPU 분석 결과:\")\n",
    "        print(f\"   📏 데이터 형태: {sample_gdf.shape}\")\n",
    "        \n",
    "        # 타겟 변수 분석\n",
    "        if 'clicked' in sample_gdf.columns:\n",
    "            click_counts = sample_gdf['clicked'].value_counts().to_pandas()\n",
    "            click_rate = sample_gdf['clicked'].mean()\n",
    "            print(f\"   🎯 클릭률: {click_rate:.4f} ({click_rate*100:.2f}%)\")\n",
    "            print(f\"   🎯 클릭 분포: {click_counts.to_dict()}\")\n",
    "        \n",
    "        # 데이터 타입 분석\n",
    "        print(f\"   📊 데이터 타입별 컬럼 수:\")\n",
    "        dtype_info = {}\n",
    "        for col in sample_gdf.columns:\n",
    "            dtype = str(sample_gdf[col].dtype)\n",
    "            dtype_info[dtype] = dtype_info.get(dtype, 0) + 1\n",
    "        \n",
    "        for dtype, count in dtype_info.items():\n",
    "            print(f\"      {dtype}: {count}개\")\n",
    "        \n",
    "        # 결측값 확인\n",
    "        null_counts = sample_gdf.isnull().sum().to_pandas()\n",
    "        null_cols = null_counts[null_counts > 0]\n",
    "        print(f\"   ❓ 결측값 있는 컬럼: {len(null_cols)}개\")\n",
    "        \n",
    "        # 카디널리티 분석 (일부 컬럼만)\n",
    "        print(f\"   🎲 카디널리티 분석 (상위 10개):\")\n",
    "        cardinality_info = {}\n",
    "        for col in sample_gdf.columns[:20]:  # 처음 20개 컬럼만\n",
    "            try:\n",
    "                unique_count = sample_gdf[col].nunique()\n",
    "                cardinality_info[col] = unique_count\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # 카디널리티 내림차순 정렬\n",
    "        sorted_cardinality = sorted(cardinality_info.items(), key=lambda x: x[1], reverse=True)\n",
    "        for col, count in sorted_cardinality[:10]:\n",
    "            print(f\"      {col}: {count}\")\n",
    "        \n",
    "        # 처리 시간 출력\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   ⏱️ 처리 시간: {elapsed:.2f}초\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del sample_gdf, first_chunk_pd\n",
    "        clear_gpu_memory()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ CuDF 분석 실패: {e}\")\n",
    "        clear_gpu_memory()\n",
    "        return fallback_pandas_analysis(file_path, sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d411ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fallback_pandas_analysis(file_path, sample_size=10000):\n",
    "    \"\"\"CuDF 실패시 Pandas 폴백\"\"\"\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import pyarrow.parquet as pq\n",
    "        \n",
    "        print(f\"🔄 Pandas 폴백 모드 (샘플 크기: {sample_size:,})\")\n",
    "        \n",
    "        # 매우 작은 샘플만 로드\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        # 첫 번째 row group에서 소량만 읽기\n",
    "        sample_df = pf.read_row_group(0).to_pandas()\n",
    "        \n",
    "        if len(sample_df) > sample_size:\n",
    "            sample_df = sample_df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        print(f\"📊 기본 정보:\")\n",
    "        print(f\"   형태: {sample_df.shape}\")\n",
    "        \n",
    "        if 'clicked' in sample_df.columns:\n",
    "            click_rate = sample_df['clicked'].mean()\n",
    "            print(f\"   클릭률: {click_rate:.4f}\")\n",
    "        \n",
    "        print(f\"   데이터 타입: {sample_df.dtypes.value_counts().to_dict()}\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del sample_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Pandas 분석도 실패: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "890f89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. NVTabular 기반 전처리 테스트\n",
    "def test_nvtabular_workflow():\n",
    "    \"\"\"NVTabular 워크플로우 테스트\"\"\"\n",
    "    \n",
    "    if not libs.get('nvtabular'):\n",
    "        print(\"❌ NVTabular 없음 - 고급 전처리 불가\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        import nvtabular as nvt\n",
    "        from nvtabular import ops\n",
    "        from merlin.io import Dataset\n",
    "        \n",
    "        print(\"🔧 NVTabular 워크플로우 테스트\")\n",
    "        \n",
    "        # 간단한 워크플로우 생성 테스트\n",
    "        # 실제 데이터 없이 구조만 확인\n",
    "        \n",
    "        # 카테고리 컬럼 정의 (일반적인 CTR 데이터 기준)\n",
    "        categorical_columns = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "        \n",
    "        # 연속형 컬럼 (예시)\n",
    "        continuous_columns = [f'feat_a_{i}' for i in range(1, 10)]\n",
    "        \n",
    "        # 워크플로우 정의\n",
    "        cat_workflow = categorical_columns >> ops.Categorify()\n",
    "        cont_workflow = continuous_columns >> ops.FillMissing() >> ops.Normalize()\n",
    "        \n",
    "        workflow = nvt.Workflow(cat_workflow + cont_workflow)\n",
    "        \n",
    "        print(\"✅ NVTabular 워크플로우 생성 성공\")\n",
    "        print(f\"   범주형 컬럼: {len(categorical_columns)}개\")\n",
    "        print(f\"   연속형 컬럼: {len(continuous_columns)}개\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ NVTabular 테스트 실패: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846c84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 메인 분석 시작\n",
      "============================================================\n",
      "🎯 GPU 메모리: 0.0GB / 24.0GB (0.0%)\n",
      "\n",
      "📊 Train 데이터 분석 시작\n",
      "🎯 CuDF 기반 샘플 분석 시작 (샘플 크기: 20,000)\n",
      "🧹 GPU 메모리 정리 완료\n",
      "   청크 크기: 10,000행\n",
      "   Pandas 청크 로드 완료: 20,000행\n",
      "   CuDF 변환 완료\n",
      "🔍 GPU 분석 결과:\n",
      "   📏 데이터 형태: (20000, 119)\n",
      "   🎯 클릭률: 0.0191 (1.91%)\n",
      "   🎯 클릭 분포: {0: 19619, 1: 381}\n",
      "   📊 데이터 타입별 컬럼 수:\n",
      "      object: 6개\n",
      "      float32: 112개\n",
      "      int32: 1개\n",
      "   ❓ 결측값 있는 컬럼: 96개\n",
      "   🎲 카디널리티 분석 (상위 10개):\n",
      "      seq: 19832\n",
      "      l_feat_12: 2120\n",
      "      l_feat_11: 1233\n",
      "      l_feat_14: 1178\n",
      "      l_feat_5: 897\n",
      "      l_feat_6: 754\n",
      "      l_feat_9: 443\n",
      "      l_feat_7: 291\n",
      "      l_feat_10: 247\n",
      "      l_feat_4: 26\n",
      "   ⏱️ 처리 시간: 89.23초\n",
      "🧹 GPU 메모리 정리 완료\n",
      "✅ 샘플 분석 완료\n",
      "\n",
      "🔧 NVTabular 환경 테스트\n",
      "❌ NVTabular 없음 - 고급 전처리 불가\n",
      "\n",
      "💡 환경별 권장사항:\n",
      "⚡ CuDF 환경 - GPU 가속 가능\n",
      "   1. DataFrame 연산 10-50배 가속\n",
      "   2. 메모리 효율적 처리\n",
      "   3. 추가 NVTabular 설치 권장\n",
      "\n",
      "🛠️ Merlin 완전 설치 가이드:\n",
      "conda create -n merlin python=3.10\n",
      "conda activate merlin\n",
      "conda install -c rapidsai -c nvidia -c conda-forge cudf=23.10 cuml\n",
      "pip install merlin-models nvtabular\n",
      "pip install xgboost lightgbm --upgrade\n",
      "🧹 GPU 메모리 정리 완료\n",
      "🎯 GPU 메모리: 0.0GB / 24.0GB (0.0%)\n",
      "\n",
      "✅ 분석 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. 실행부\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎯 메인 분석 시작\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # GPU 메모리 초기 상태\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # 파일이 존재하는 경우에만 분석 진행\n",
    "    if train_info:\n",
    "        print(f\"\\n📊 Train 데이터 분석 시작\")\n",
    "        success = cudf_safe_sample_analysis('../data/train.parquet', sample_size=20000)\n",
    "        \n",
    "        if success:\n",
    "            print(\"✅ 샘플 분석 완료\")\n",
    "        else:\n",
    "            print(\"❌ 분석 실패 - 환경 설정을 확인해주세요\")\n",
    "    \n",
    "    # NVTabular 테스트\n",
    "    print(f\"\\n🔧 NVTabular 환경 테스트\")\n",
    "    nvt_success = test_nvtabular_workflow()\n",
    "    \n",
    "    # 최종 권장사항\n",
    "    print(f\"\\n💡 환경별 권장사항:\")\n",
    "    \n",
    "    if libs.get('cudf') and libs.get('nvtabular'):\n",
    "        print(\"🚀 완전한 Merlin 환경 - 최적 성능 가능\")\n",
    "        print(\"   1. 전체 데이터 GPU 처리 가능\")\n",
    "        print(\"   2. Out-of-core 처리로 메모리 안전\")\n",
    "        print(\"   3. XGBoost GPU 가속 추천\")\n",
    "    elif libs.get('cudf'):\n",
    "        print(\"⚡ CuDF 환경 - GPU 가속 가능\")\n",
    "        print(\"   1. DataFrame 연산 10-50배 가속\")\n",
    "        print(\"   2. 메모리 효율적 처리\")\n",
    "        print(\"   3. 추가 NVTabular 설치 권장\")\n",
    "    else:\n",
    "        print(\"🐌 기본 환경 - CPU 기반 처리\")\n",
    "        print(\"   1. 청크 단위 처리 필수\")\n",
    "        print(\"   2. 샘플링 기반 분석\")\n",
    "        print(\"   3. Merlin 환경 구축 강력 권장\")\n",
    "    \n",
    "    print(f\"\\n🛠️ Merlin 완전 설치 가이드:\")\n",
    "    print(\"conda create -n merlin python=3.10\")\n",
    "    print(\"conda activate merlin\")\n",
    "    print(\"conda install -c rapidsai -c nvidia -c conda-forge cudf=23.10 cuml\")\n",
    "    print(\"pip install merlin-models nvtabular\")\n",
    "    print(\"pip install xgboost lightgbm --upgrade\")\n",
    "    \n",
    "    # 최종 메모리 정리\n",
    "    clear_gpu_memory()\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    print(\"\\n✅ 분석 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
