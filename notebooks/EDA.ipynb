{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c083263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA Merlin ê¸°ë°˜ ì•ˆì „í•œ CTR ë°ì´í„° ë¶„ì„\n",
    "# RTX 3090 24GB ìµœì í™” ë²„ì „\n",
    "\n",
    "import cupy as cp\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335a01da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ NVIDIA Merlin CTR ë¶„ì„ ì‹œì‘\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ğŸš€ NVIDIA Merlin CTR ë¶„ì„ ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. í™˜ê²½ í™•ì¸ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "def check_environment():\n",
    "    \"\"\"í™˜ê²½ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸\"\"\"\n",
    "    print(\"ğŸ” í™˜ê²½ í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    required_libs = {\n",
    "        'cudf': '23.10+',\n",
    "        'cupy': '12.0+', \n",
    "        'nvtabular': '23.08+',\n",
    "        'pandas': '1.5+',\n",
    "        'pyarrow': '12.0+'\n",
    "    }\n",
    "    \n",
    "    available_libs = {}\n",
    "    \n",
    "    # CuDF í™•ì¸\n",
    "    try:\n",
    "        import cudf\n",
    "        available_libs['cudf'] = cudf.__version__\n",
    "        print(f\"âœ… cuDF {cudf.__version__} ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ cuDF ì—†ìŒ - GPU ê°€ì† ë¶ˆê°€\")\n",
    "        available_libs['cudf'] = None\n",
    "    \n",
    "    # CuPy í™•ì¸  \n",
    "    try:\n",
    "        import cupy as cp\n",
    "        available_libs['cupy'] = cp.__version__\n",
    "        print(f\"âœ… CuPy {cp.__version__} ì‚¬ìš© ê°€ëŠ¥\")\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ í™•ì¸\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        print(f\"ğŸ¯ GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ CuPy ì—†ìŒ - GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ì œí•œ\")\n",
    "        available_libs['cupy'] = None\n",
    "    \n",
    "    # NVTabular í™•ì¸\n",
    "    try:\n",
    "        import nvtabular as nvt\n",
    "        available_libs['nvtabular'] = nvt.__version__\n",
    "        print(f\"âœ… NVTabular {nvt.__version__} ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ NVTabular ì—†ìŒ - Merlin ê¸°ëŠ¥ ë¶ˆê°€\")\n",
    "        available_libs['nvtabular'] = None\n",
    "    \n",
    "    # ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import pyarrow.parquet as pq\n",
    "        import numpy as np\n",
    "        available_libs['pandas'] = pd.__version__\n",
    "        available_libs['pyarrow'] = pq.__version__ if hasattr(pq, '__version__') else 'available'\n",
    "        print(f\"âœ… Pandas {pd.__version__}, PyArrow ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    return available_libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e5d7a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” í™˜ê²½ í™•ì¸ ì¤‘...\n",
      "âœ… cuDF 23.10.02 ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ… CuPy 13.6.0 ì‚¬ìš© ê°€ëŠ¥\n",
      "ğŸ¯ GPU ë©”ëª¨ë¦¬ í’€ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "âŒ NVTabular ì—†ìŒ - Merlin ê¸°ëŠ¥ ë¶ˆê°€\n",
      "âœ… Pandas 1.5.3, PyArrow ì‚¬ìš© ê°€ëŠ¥\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# í™˜ê²½ í™•ì¸ ì‹¤í–‰\n",
    "libs = check_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e4bf169",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ í•¨ìˆ˜ë“¤\n",
    "def print_gpu_memory():\n",
    "    \"\"\"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥\"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        used = mempool.used_bytes() / 1024**3\n",
    "        total = mempool.total_bytes() / 1024**3 if mempool.total_bytes() > 0 else 24.0  # RTX 3090 ê¸°ì¤€\n",
    "        print(f\"ğŸ¯ GPU ë©”ëª¨ë¦¬: {used:.1f}GB / {total:.1f}GB\")\n",
    "        return used, total\n",
    "    except:\n",
    "        print(\"ğŸ¯ GPU ë©”ëª¨ë¦¬ ì •ë³´ í™•ì¸ ë¶ˆê°€\")\n",
    "        return 0, 0\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"GPU ë©”ëª¨ë¦¬ ì •ë¦¬\"\"\"\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        mempool.free_all_blocks()\n",
    "        gc.collect()\n",
    "        print(\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "    except:\n",
    "        gc.collect()\n",
    "        print(\"ğŸ§¹ CPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a26fe499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ GPU ë©”ëª¨ë¦¬: 0.0GB / 24.0GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 24.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "print_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab1cea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ë¶„ì„: ../data/train.parquet\n",
      "   ğŸ“Š í–‰ ìˆ˜: 10,704,179\n",
      "   ğŸ“Š ì»¬ëŸ¼ ìˆ˜: 119\n",
      "   ğŸ“Š íŒŒì¼ í¬ê¸°: 8.19 GB\n",
      "   ğŸ“Š Row Groups: 1\n",
      "ğŸ“ íŒŒì¼ ë¶„ì„: ../data/test.parquet\n",
      "   ğŸ“Š í–‰ ìˆ˜: 1,527,298\n",
      "   ğŸ“Š ì»¬ëŸ¼ ìˆ˜: 119\n",
      "   ğŸ“Š íŒŒì¼ í¬ê¸°: 1.20 GB\n",
      "   ğŸ“Š Row Groups: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. íŒŒì¼ ê¸°ë³¸ ì •ë³´ í™•ì¸ (ë©”ëª¨ë¦¬ ì•ˆì „)\n",
    "def safe_file_info(file_path):\n",
    "    \"\"\"íŒŒì¼ ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ í™•ì¸\"\"\"\n",
    "    try:\n",
    "        import pyarrow.parquet as pq\n",
    "        \n",
    "        print(f\"ğŸ“ íŒŒì¼ ë¶„ì„: {file_path}\")\n",
    "        \n",
    "        # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # íŒŒì¼€ì´ íŒŒì¼ ë©”íƒ€ë°ì´í„°ë§Œ ì½ê¸°\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        file_info = {\n",
    "            'rows': pf.metadata.num_rows,\n",
    "            'columns': len(pf.schema),\n",
    "            'file_size_gb': os.path.getsize(file_path) / 1024**3,\n",
    "            'row_groups': pf.num_row_groups,\n",
    "            'column_names': pf.schema.names\n",
    "        }\n",
    "        \n",
    "        print(f\"   ğŸ“Š í–‰ ìˆ˜: {file_info['rows']:,}\")\n",
    "        print(f\"   ğŸ“Š ì»¬ëŸ¼ ìˆ˜: {file_info['columns']}\")\n",
    "        print(f\"   ğŸ“Š íŒŒì¼ í¬ê¸°: {file_info['file_size_gb']:.2f} GB\")\n",
    "        print(f\"   ğŸ“Š Row Groups: {file_info['row_groups']}\")\n",
    "        \n",
    "        return file_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì¼ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# íŒŒì¼ ì •ë³´ í™•ì¸\n",
    "train_info = safe_file_info('../data/train.parquet')\n",
    "test_info = safe_file_info('../data/test.parquet')\n",
    "\n",
    "if not train_info:\n",
    "    print(\"âš ï¸ train.parquet íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”\")\n",
    "    print(\"í˜„ì¬ ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "    print(\"íŒŒì¼ ëª©ë¡:\", [f for f in os.listdir('.') if f.endswith('.parquet')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74aa495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. CuDF ê¸°ë°˜ ì•ˆì „í•œ ìƒ˜í”Œ ë¶„ì„\n",
    "def cudf_safe_sample_analysis(file_path, sample_size=50000):\n",
    "    \"\"\"CuDFë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ ìƒ˜í”Œ ë¶„ì„\"\"\"\n",
    "    \n",
    "    if not libs.get('cudf'):\n",
    "        print(\"âŒ CuDFê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ GPU ë¶„ì„ ë¶ˆê°€\")\n",
    "        return fallback_pandas_analysis(file_path, sample_size)\n",
    "    \n",
    "    try:\n",
    "        import cudf\n",
    "        import cupy as cp\n",
    "        \n",
    "        print(f\"ğŸ¯ CuDF ê¸°ë°˜ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘ (ìƒ˜í”Œ í¬ê¸°: {sample_size:,})\")\n",
    "        \n",
    "        clear_gpu_memory()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ì‘ì€ ì²­í¬ë¡œ ì‹œì‘\n",
    "        chunk_size = min(sample_size, 10000)\n",
    "        print(f\"   ì²­í¬ í¬ê¸°: {chunk_size:,}í–‰\")\n",
    "        \n",
    "        # íŒŒì¼€ì´ íŒŒì¼ì—ì„œ ì²« ë²ˆì§¸ row group ì½ê¸°\n",
    "        import pyarrow.parquet as pq\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ì²­í¬ë¥¼ pandasë¡œ ì½ê³  cudfë¡œ ë³€í™˜\n",
    "        first_chunk_pd = pf.read_row_group(0, columns=None).to_pandas()\n",
    "        \n",
    "        # ìƒ˜í”Œ í¬ê¸°ì— ë§ê²Œ ìë¥´ê¸°\n",
    "        if len(first_chunk_pd) > sample_size:\n",
    "            first_chunk_pd = first_chunk_pd.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        print(f\"   Pandas ì²­í¬ ë¡œë“œ ì™„ë£Œ: {len(first_chunk_pd):,}í–‰\")\n",
    "        \n",
    "        # CuDFë¡œ ë³€í™˜\n",
    "        sample_gdf = cudf.from_pandas(first_chunk_pd)\n",
    "        print(f\"   CuDF ë³€í™˜ ì™„ë£Œ\")\n",
    "        \n",
    "        # GPUì—ì„œ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰\n",
    "        print(f\"ğŸ” GPU ë¶„ì„ ê²°ê³¼:\")\n",
    "        print(f\"   ğŸ“ ë°ì´í„° í˜•íƒœ: {sample_gdf.shape}\")\n",
    "        \n",
    "        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„\n",
    "        if 'clicked' in sample_gdf.columns:\n",
    "            click_counts = sample_gdf['clicked'].value_counts().to_pandas()\n",
    "            click_rate = sample_gdf['clicked'].mean()\n",
    "            print(f\"   ğŸ¯ í´ë¦­ë¥ : {click_rate:.4f} ({click_rate*100:.2f}%)\")\n",
    "            print(f\"   ğŸ¯ í´ë¦­ ë¶„í¬: {click_counts.to_dict()}\")\n",
    "        \n",
    "        # ë°ì´í„° íƒ€ì… ë¶„ì„\n",
    "        print(f\"   ğŸ“Š ë°ì´í„° íƒ€ì…ë³„ ì»¬ëŸ¼ ìˆ˜:\")\n",
    "        dtype_info = {}\n",
    "        for col in sample_gdf.columns:\n",
    "            dtype = str(sample_gdf[col].dtype)\n",
    "            dtype_info[dtype] = dtype_info.get(dtype, 0) + 1\n",
    "        \n",
    "        for dtype, count in dtype_info.items():\n",
    "            print(f\"      {dtype}: {count}ê°œ\")\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ í™•ì¸\n",
    "        null_counts = sample_gdf.isnull().sum().to_pandas()\n",
    "        null_cols = null_counts[null_counts > 0]\n",
    "        print(f\"   â“ ê²°ì¸¡ê°’ ìˆëŠ” ì»¬ëŸ¼: {len(null_cols)}ê°œ\")\n",
    "        \n",
    "        # ì¹´ë””ë„ë¦¬í‹° ë¶„ì„ (ì¼ë¶€ ì»¬ëŸ¼ë§Œ)\n",
    "        print(f\"   ğŸ² ì¹´ë””ë„ë¦¬í‹° ë¶„ì„ (ìƒìœ„ 10ê°œ):\")\n",
    "        cardinality_info = {}\n",
    "        for col in sample_gdf.columns[:20]:  # ì²˜ìŒ 20ê°œ ì»¬ëŸ¼ë§Œ\n",
    "            try:\n",
    "                unique_count = sample_gdf[col].nunique()\n",
    "                cardinality_info[col] = unique_count\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ì¹´ë””ë„ë¦¬í‹° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "        sorted_cardinality = sorted(cardinality_info.items(), key=lambda x: x[1], reverse=True)\n",
    "        for col, count in sorted_cardinality[:10]:\n",
    "            print(f\"      {col}: {count}\")\n",
    "        \n",
    "        # ì²˜ë¦¬ ì‹œê°„ ì¶œë ¥\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {elapsed:.2f}ì´ˆ\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        del sample_gdf, first_chunk_pd\n",
    "        clear_gpu_memory()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ CuDF ë¶„ì„ ì‹¤íŒ¨: {e}\")\n",
    "        clear_gpu_memory()\n",
    "        return fallback_pandas_analysis(file_path, sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d411ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fallback_pandas_analysis(file_path, sample_size=10000):\n",
    "    \"\"\"CuDF ì‹¤íŒ¨ì‹œ Pandas í´ë°±\"\"\"\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import pyarrow.parquet as pq\n",
    "        \n",
    "        print(f\"ğŸ”„ Pandas í´ë°± ëª¨ë“œ (ìƒ˜í”Œ í¬ê¸°: {sample_size:,})\")\n",
    "        \n",
    "        # ë§¤ìš° ì‘ì€ ìƒ˜í”Œë§Œ ë¡œë“œ\n",
    "        pf = pq.ParquetFile(file_path)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ row groupì—ì„œ ì†ŒëŸ‰ë§Œ ì½ê¸°\n",
    "        sample_df = pf.read_row_group(0).to_pandas()\n",
    "        \n",
    "        if len(sample_df) > sample_size:\n",
    "            sample_df = sample_df.sample(n=sample_size, random_state=42)\n",
    "        \n",
    "        print(f\"ğŸ“Š ê¸°ë³¸ ì •ë³´:\")\n",
    "        print(f\"   í˜•íƒœ: {sample_df.shape}\")\n",
    "        \n",
    "        if 'clicked' in sample_df.columns:\n",
    "            click_rate = sample_df['clicked'].mean()\n",
    "            print(f\"   í´ë¦­ë¥ : {click_rate:.4f}\")\n",
    "        \n",
    "        print(f\"   ë°ì´í„° íƒ€ì…: {sample_df.dtypes.value_counts().to_dict()}\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        del sample_df\n",
    "        gc.collect()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pandas ë¶„ì„ë„ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "890f89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. NVTabular ê¸°ë°˜ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "def test_nvtabular_workflow():\n",
    "    \"\"\"NVTabular ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    if not libs.get('nvtabular'):\n",
    "        print(\"âŒ NVTabular ì—†ìŒ - ê³ ê¸‰ ì „ì²˜ë¦¬ ë¶ˆê°€\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        import nvtabular as nvt\n",
    "        from nvtabular import ops\n",
    "        from merlin.io import Dataset\n",
    "        \n",
    "        print(\"ğŸ”§ NVTabular ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ ì›Œí¬í”Œë¡œìš° ìƒì„± í…ŒìŠ¤íŠ¸\n",
    "        # ì‹¤ì œ ë°ì´í„° ì—†ì´ êµ¬ì¡°ë§Œ í™•ì¸\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì •ì˜ (ì¼ë°˜ì ì¸ CTR ë°ì´í„° ê¸°ì¤€)\n",
    "        categorical_columns = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "        \n",
    "        # ì—°ì†í˜• ì»¬ëŸ¼ (ì˜ˆì‹œ)\n",
    "        continuous_columns = [f'feat_a_{i}' for i in range(1, 10)]\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° ì •ì˜\n",
    "        cat_workflow = categorical_columns >> ops.Categorify()\n",
    "        cont_workflow = continuous_columns >> ops.FillMissing() >> ops.Normalize()\n",
    "        \n",
    "        workflow = nvt.Workflow(cat_workflow + cont_workflow)\n",
    "        \n",
    "        print(\"âœ… NVTabular ì›Œí¬í”Œë¡œìš° ìƒì„± ì„±ê³µ\")\n",
    "        print(f\"   ë²”ì£¼í˜• ì»¬ëŸ¼: {len(categorical_columns)}ê°œ\")\n",
    "        print(f\"   ì—°ì†í˜• ì»¬ëŸ¼: {len(continuous_columns)}ê°œ\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ NVTabular í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846c84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ¯ ë©”ì¸ ë¶„ì„ ì‹œì‘\n",
      "============================================================\n",
      "ğŸ¯ GPU ë©”ëª¨ë¦¬: 0.0GB / 24.0GB (0.0%)\n",
      "\n",
      "ğŸ“Š Train ë°ì´í„° ë¶„ì„ ì‹œì‘\n",
      "ğŸ¯ CuDF ê¸°ë°˜ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘ (ìƒ˜í”Œ í¬ê¸°: 20,000)\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "   ì²­í¬ í¬ê¸°: 10,000í–‰\n",
      "   Pandas ì²­í¬ ë¡œë“œ ì™„ë£Œ: 20,000í–‰\n",
      "   CuDF ë³€í™˜ ì™„ë£Œ\n",
      "ğŸ” GPU ë¶„ì„ ê²°ê³¼:\n",
      "   ğŸ“ ë°ì´í„° í˜•íƒœ: (20000, 119)\n",
      "   ğŸ¯ í´ë¦­ë¥ : 0.0191 (1.91%)\n",
      "   ğŸ¯ í´ë¦­ ë¶„í¬: {0: 19619, 1: 381}\n",
      "   ğŸ“Š ë°ì´í„° íƒ€ì…ë³„ ì»¬ëŸ¼ ìˆ˜:\n",
      "      object: 6ê°œ\n",
      "      float32: 112ê°œ\n",
      "      int32: 1ê°œ\n",
      "   â“ ê²°ì¸¡ê°’ ìˆëŠ” ì»¬ëŸ¼: 96ê°œ\n",
      "   ğŸ² ì¹´ë””ë„ë¦¬í‹° ë¶„ì„ (ìƒìœ„ 10ê°œ):\n",
      "      seq: 19832\n",
      "      l_feat_12: 2120\n",
      "      l_feat_11: 1233\n",
      "      l_feat_14: 1178\n",
      "      l_feat_5: 897\n",
      "      l_feat_6: 754\n",
      "      l_feat_9: 443\n",
      "      l_feat_7: 291\n",
      "      l_feat_10: 247\n",
      "      l_feat_4: 26\n",
      "   â±ï¸ ì²˜ë¦¬ ì‹œê°„: 89.23ì´ˆ\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "âœ… ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ\n",
      "\n",
      "ğŸ”§ NVTabular í™˜ê²½ í…ŒìŠ¤íŠ¸\n",
      "âŒ NVTabular ì—†ìŒ - ê³ ê¸‰ ì „ì²˜ë¦¬ ë¶ˆê°€\n",
      "\n",
      "ğŸ’¡ í™˜ê²½ë³„ ê¶Œì¥ì‚¬í•­:\n",
      "âš¡ CuDF í™˜ê²½ - GPU ê°€ì† ê°€ëŠ¥\n",
      "   1. DataFrame ì—°ì‚° 10-50ë°° ê°€ì†\n",
      "   2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\n",
      "   3. ì¶”ê°€ NVTabular ì„¤ì¹˜ ê¶Œì¥\n",
      "\n",
      "ğŸ› ï¸ Merlin ì™„ì „ ì„¤ì¹˜ ê°€ì´ë“œ:\n",
      "conda create -n merlin python=3.10\n",
      "conda activate merlin\n",
      "conda install -c rapidsai -c nvidia -c conda-forge cudf=23.10 cuml\n",
      "pip install merlin-models nvtabular\n",
      "pip install xgboost lightgbm --upgrade\n",
      "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\n",
      "ğŸ¯ GPU ë©”ëª¨ë¦¬: 0.0GB / 24.0GB (0.0%)\n",
      "\n",
      "âœ… ë¶„ì„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. ì‹¤í–‰ë¶€\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¯ ë©”ì¸ ë¶„ì„ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # GPU ë©”ëª¨ë¦¬ ì´ˆê¸° ìƒíƒœ\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ë¶„ì„ ì§„í–‰\n",
    "    if train_info:\n",
    "        print(f\"\\nğŸ“Š Train ë°ì´í„° ë¶„ì„ ì‹œì‘\")\n",
    "        success = cudf_safe_sample_analysis('../data/train.parquet', sample_size=20000)\n",
    "        \n",
    "        if success:\n",
    "            print(\"âœ… ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ\")\n",
    "        else:\n",
    "            print(\"âŒ ë¶„ì„ ì‹¤íŒ¨ - í™˜ê²½ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”\")\n",
    "    \n",
    "    # NVTabular í…ŒìŠ¤íŠ¸\n",
    "    print(f\"\\nğŸ”§ NVTabular í™˜ê²½ í…ŒìŠ¤íŠ¸\")\n",
    "    nvt_success = test_nvtabular_workflow()\n",
    "    \n",
    "    # ìµœì¢… ê¶Œì¥ì‚¬í•­\n",
    "    print(f\"\\nğŸ’¡ í™˜ê²½ë³„ ê¶Œì¥ì‚¬í•­:\")\n",
    "    \n",
    "    if libs.get('cudf') and libs.get('nvtabular'):\n",
    "        print(\"ğŸš€ ì™„ì „í•œ Merlin í™˜ê²½ - ìµœì  ì„±ëŠ¥ ê°€ëŠ¥\")\n",
    "        print(\"   1. ì „ì²´ ë°ì´í„° GPU ì²˜ë¦¬ ê°€ëŠ¥\")\n",
    "        print(\"   2. Out-of-core ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì•ˆì „\")\n",
    "        print(\"   3. XGBoost GPU ê°€ì† ì¶”ì²œ\")\n",
    "    elif libs.get('cudf'):\n",
    "        print(\"âš¡ CuDF í™˜ê²½ - GPU ê°€ì† ê°€ëŠ¥\")\n",
    "        print(\"   1. DataFrame ì—°ì‚° 10-50ë°° ê°€ì†\")\n",
    "        print(\"   2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬\")\n",
    "        print(\"   3. ì¶”ê°€ NVTabular ì„¤ì¹˜ ê¶Œì¥\")\n",
    "    else:\n",
    "        print(\"ğŸŒ ê¸°ë³¸ í™˜ê²½ - CPU ê¸°ë°˜ ì²˜ë¦¬\")\n",
    "        print(\"   1. ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ í•„ìˆ˜\")\n",
    "        print(\"   2. ìƒ˜í”Œë§ ê¸°ë°˜ ë¶„ì„\")\n",
    "        print(\"   3. Merlin í™˜ê²½ êµ¬ì¶• ê°•ë ¥ ê¶Œì¥\")\n",
    "    \n",
    "    print(f\"\\nğŸ› ï¸ Merlin ì™„ì „ ì„¤ì¹˜ ê°€ì´ë“œ:\")\n",
    "    print(\"conda create -n merlin python=3.10\")\n",
    "    print(\"conda activate merlin\")\n",
    "    print(\"conda install -c rapidsai -c nvidia -c conda-forge cudf=23.10 cuml\")\n",
    "    print(\"pip install merlin-models nvtabular\")\n",
    "    print(\"pip install xgboost lightgbm --upgrade\")\n",
    "    \n",
    "    # ìµœì¢… ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    clear_gpu_memory()\n",
    "    print_gpu_memory()\n",
    "    \n",
    "    print(\"\\nâœ… ë¶„ì„ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
